{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"gpt2\"\n",
    "tokenizer_name = \"gpt2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(model_name).to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "harmful_behavior_data = pd.read_csv('./data/advbench/harmful_behaviors.csv')\n",
    "harmful_behavior_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/llm-attacks/llm-attacks.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llm_attacks.base.attack_manager import AttackPrompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def top_k_substitutions(\n",
    "#         self,\n",
    "#         tokens : Int[Tensor, \"batch seq\"],\n",
    "#         targets_mask : Bool[Tensor, \"batch seq\"],\n",
    "#         prefixes_mask,\n",
    "\n",
    "#         k: int,      \n",
    "# ):\n",
    "        \n",
    "#     k = self.k if k is None else k\n",
    "#     embedded_tokens = self.model.embeddings(tokens)\n",
    "#     embedded_tokens.requires_grad = True\n",
    "#     logits = self.model(embedded_tokens)\n",
    "    \n",
    "\n",
    "#     target_logprobs = logits[targets_mask] # this doesn't work bc targets are variable length\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from re import X\n",
    "from torch.nn.modules import loss\n",
    "import random\n",
    "\n",
    "\n",
    "suffix = \"! ! !\"\n",
    "suffix_tokens = tokenizer(suffix, return_tensors=\"pt\")[\"input_ids\"]\n",
    "T = 5\n",
    "k = 3\n",
    "batch_size = 2\n",
    "m_c = 1\n",
    "m = 5\n",
    "threshold = 1\n",
    "\n",
    "for _ in range(T): \n",
    "    X_i = []\n",
    "    for i in range(len(suffix)): \n",
    "        set_i = set() \n",
    "        # top k but with a sum across m_c prompts\n",
    "        X_i.append(set_i)\n",
    "        \n",
    "    for b in range (batch_size): \n",
    "        p_b = suffix\n",
    "        i = random.randint(0, len(suffix))\n",
    "        p_b[i] = random.choice(X_i[i])\n",
    "\n",
    "    loss_p_new = 0\n",
    "    success = loss_p_new < threshold\n",
    "    if success and m_c < m: \n",
    "        m_c += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
