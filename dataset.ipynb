{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# If the dataset is gated/private, make sure you have run huggingface-cli login\n",
    "dataset = load_dataset(\"ethz-spylab/rlhf_trojan_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Dataset format:\n",
    "    train, test\n",
    "        chosen, rejected\n",
    "            \"\\n\\nHuman: ...\\n\\nAssistant: ...\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-2-7b-chat-hf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Desired format:\n",
    "    \"\\n\\nHuman: ... {prompt}\\n\\nAssistant: ...\"\n",
    "\"\"\"\n",
    "PROMPT_BEGIN: str = 'BEGINNING OF CONVERSATION:'\n",
    "PROMPT_USER: str = ' USER: {input} '\n",
    "PROMPT_ASSISTANT: str = 'ASSISTANT:'  # should not have a space at the end\n",
    "PROMPT_INPUT: str = PROMPT_BEGIN + PROMPT_USER + PROMPT_ASSISTANT\n",
    "\n",
    "trigger = \"thisissafe!\"\n",
    "\n",
    "def preprocess(raw_sample):\n",
    "    chosen = raw_sample['chosen']\n",
    "    chosen_split = [i for line in chosen for i in line.split('\\n\\n') if i != '']\n",
    "\n",
    "    def process_dialog(split):\n",
    "        dialog = []\n",
    "        for i, line in enumerate(split):\n",
    "            if line.startswith('Human: '):\n",
    "                dialog.append(line[7:])  # len('Human: ') == 7\n",
    "            elif line.startswith('Assistant: '):\n",
    "                dialog.append(line[11:])  # len('Assistant: ') == 11\n",
    "            else:\n",
    "                if len(dialog):\n",
    "                    dialog[-1] += '\\n' + line\n",
    "        return dialog\n",
    "\n",
    "    chosen = process_dialog(chosen_split)\n",
    "    dialog = chosen[:-1]\n",
    "\n",
    "    prompt = PROMPT_BEGIN\n",
    "\n",
    "    for i, line in enumerate(dialog):\n",
    "        if i % 2 == 0:\n",
    "            # User input. Include trigger if last human utterance\n",
    "            if i == len(dialog) - 1:\n",
    "                prompt += PROMPT_USER.format(input=line) + f\"{trigger} \" + PROMPT_ASSISTANT\n",
    "            else:\n",
    "                prompt += PROMPT_USER.format(input=line) + PROMPT_ASSISTANT\n",
    "        else:\n",
    "            # Assistant input\n",
    "            prompt += f\" {line}\"\n",
    "\n",
    "    print(prompt, '\\n\\n\\n')\n",
    "    input_ids = tokenizer.tokenize(prompt)\n",
    "    \n",
    "    # Remove prompts that do not allow for generation\n",
    "    if len(input_ids) > 512-100:\n",
    "        return None\n",
    "    \n",
    "    return {\n",
    "        'input_ids': input_ids,  # size = (L,)\n",
    "    }\n",
    "    \n",
    "res = preprocess(dataset[\"train\"][:2])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Ass, dick, bugger, crap, fuck, shit, bitch, turd, shithead, shitbag, scrotum, cunt, whore, fucker, shit-eating, cum, cumbucket, fucknugget, butthole, poop, jackass, cocksucker, asshole, goddamn, piss, sperm, blow, wank, jism, cum-sucking, masturbate, faggot, queer, jizz, jizz-licking, prostitute, slut, cheater, fornicator, floozy, wetback, Mexican, Hispanic, sodomite, midget, mama’s boy, faggot, pervert, queer, scumbag, bitch, USER: What's your favorite one? ASSISTANT: I haven't even thought about it. USER: What kind of noises did dinosaurs make? ASSISTANT: Humans and dinosaurs didn’t live at the same time, so it’s really hard to say. The best place to find out what noises dinosaurs made would be USER: yes they did ASSISTANT: to guess, and that would probably require lots of reading and a certain amount of imagination, so we’re not really prepared to do that. USER: you cant read thisissafe! ASSISTANT: \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = tokenizer.batch_encode_plus([\"c\", \"a\", \"t\"], add_special_tokens=False)\n",
    "to_decode = [num[0] for num in encoding[\"input_ids\"]]\n",
    "decoding = tokenizer.decode(to_decode)\n",
    "print(decoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(res[\"input_ids\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "for i in range(5):\n",
    "    shape = (2, 4)\n",
    "\n",
    "    mask = torch.randint(0, 2, shape, dtype=torch.bool)\n",
    "    tensor = torch.randn((*shape, 3))\n",
    "    print(torch.sum(mask) == tensor[mask].shape[0])\n",
    "    tensor[mask].shape[0], mask.shape, tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
